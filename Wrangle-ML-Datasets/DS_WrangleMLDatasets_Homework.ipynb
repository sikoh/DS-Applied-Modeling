{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiHzbgUAw-6R"
      },
      "source": [
        "# Wrangle ML datasets\n",
        "- Explore tabular data for supervised machine learning\n",
        "- Join relational data for supervised machine learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3Sn-sQnU7OH"
      },
      "source": [
        "# Explore tabular data for supervised machine learning 🍌"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIhIfXoaw-6S"
      },
      "source": [
        "Wrangling your dataset is often the most challenging and time-consuming part of the modeling process.\n",
        "\n",
        "In today's lesson, we’ll work with a dataset of [3 Million Instacart Orders, Open Sourced](https://tech.instacart.com/3-million-instacart-orders-open-sourced-d40d29ead6f2)!\n",
        "\n",
        "Let’s get set up:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDhEvgSew-6T"
      },
      "outputs": [],
      "source": [
        "# Download data\n",
        "import requests\n",
        "\n",
        "def download(url):\n",
        "    filename = url.split('/')[-1]\n",
        "    print(f'Downloading {url}')\n",
        "    r = requests.get(url)\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(r.content)\n",
        "    print(f'Downloaded {filename}')\n",
        "\n",
        "download('https://lambdaschool-ds-instruction.s3.amazonaws.com/datasets%3Ainstacart_2017_05_01.tar.gz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5LQpRMtw-6W"
      },
      "outputs": [],
      "source": [
        "# Uncompress data\n",
        "import tarfile\n",
        "tarfile.open('datasets%3Ainstacart_2017_05_01.tar.gz').extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfhCZMj2w-6X"
      },
      "outputs": [],
      "source": [
        "# Change directory to where the data was uncompressed\n",
        "%cd instacart_2017_05_01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJHLCinIw-6Z"
      },
      "outputs": [],
      "source": [
        "# Print the csv filenames\n",
        "from glob import glob\n",
        "for filename in glob('*.csv'):\n",
        "    print(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LS6c-xpUw-6b"
      },
      "outputs": [],
      "source": [
        "# For each csv file, look at its shape & head\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRDsZMPnw-6d"
      },
      "source": [
        "### The original task was complex ...\n",
        "\n",
        "[The Kaggle competition said,](https://www.kaggle.com/c/instacart-market-basket-analysis/data):\n",
        "\n",
        "> The dataset for this competition is a relational set of files describing customers' orders over time. The goal of the competition is to predict which products will be in a user's next order.\n",
        "\n",
        "> orders.csv: This file tells to which set (prior, train, test) an order belongs. You are predicting reordered items only for the test set orders.\n",
        "\n",
        "Each row in the submission is an order_id from the test set, followed by product_id(s) predicted to be reordered.\n",
        "\n",
        "> sample_submission.csv:\n",
        "```\n",
        "order_id,products\n",
        "17,39276 29259\n",
        "34,39276 29259\n",
        "137,39276 29259\n",
        "182,39276 29259\n",
        "257,39276 29259\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VF8Lw_dw-6d"
      },
      "source": [
        "### ... but we can simplify!\n",
        "\n",
        "Simplify the question, from \"Which products will be reordered?\" (Multi-class, [multi-label](https://en.wikipedia.org/wiki/Multi-label_classification) classification) to **\"Will customers reorder this one product?\"** (Binary classification)\n",
        "\n",
        "Which product? How about **the most frequently ordered product?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-iS4YGgw-6e"
      },
      "source": [
        "### Questions:\n",
        "\n",
        "- What is the most frequently ordered product?\n",
        "- How often is this product included in a customer's next order?\n",
        "- Which customers have ordered this product before?\n",
        "- How can we get a subset of data, just for these customers?\n",
        "- What features can we engineer? We want to predict, will these customers reorder this product on their next order?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sehp0GZsU7OL"
      },
      "source": [
        "## Follow Along"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFvtqzBQw-6e"
      },
      "source": [
        "### What was the most frequently ordered product?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lS3CPuksw-6f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56eJ-Gkdw-6g"
      },
      "source": [
        "### How often are bananas included in a customer's next order?\n",
        "\n",
        "There are [three sets of data](https://gist.github.com/jeremystan/c3b39d947d9b88b3ccff3147dbcf6c6b):\n",
        "\n",
        "> \"prior\": orders prior to that users most recent order (3.2m orders)  \n",
        "\"train\": training data supplied to participants (131k orders)  \n",
        "\"test\": test data reserved for machine learning competitions (75k orders)\n",
        "\n",
        "Customers' next orders are in the \"train\" and \"test\" sets. (The \"prior\" set has the orders prior to the most recent orders.)\n",
        "\n",
        "We can't use the \"test\" set here, because we don't have its labels (only Kaggle & Instacart have them), so we don't know what products were bought in the \"test\" set orders.\n",
        "\n",
        "So, we'll use the \"train\" set. It currently has one row per product_id and multiple rows per order_id.\n",
        "\n",
        "But we don't want that. Instead we want one row per order_id, with a binary column: \"Did the order include bananas?\"\n",
        "\n",
        "Let's wrangle!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWaneblAAp0f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TP9gFbdJU7OM"
      },
      "source": [
        "# Join relational data for supervised machine learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5msGaMsoU7OM"
      },
      "source": [
        "## Overview\n",
        "Often, you’ll need to join data from multiple relational tables before you’re ready to fit your models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbOI93-Sw-6i"
      },
      "source": [
        "### Which customers have ordered this product before?\n",
        "\n",
        "- Customers are identified by `user_id`\n",
        "- Products are identified by `product_id`\n",
        "\n",
        "Do we have a table with both these id's? (If not, how can we combine this information?)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F98dwqAUw-6j"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XOVZaJmU7OM"
      },
      "source": [
        "## Follow Along"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCy_4L_tw-6k"
      },
      "source": [
        "### How can we get a subset of data, just for these customers?\n",
        "\n",
        "We want *all* the orders from customers who have *ever* bought bananas.\n",
        "\n",
        "(And *none* of the orders from customers who have *never* bought bananas.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKlvuzBSw-6l"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kh5Xhqrpw-6m"
      },
      "source": [
        "### What features can we engineer? We want to predict, will these customers reorder bananas on their next order?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uluspye5LQAI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKJOkbxbU7ON"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "**Continue to clean and explore your data.** Can you **engineer features** to help predict your target? For the evaluation metric you chose, what score would you get just by guessing? Can you **make a fast, first model** that beats guessing?\n",
        "\n",
        "We recommend that you use your portfolio project dataset for all assignments this sprint. But if you aren't ready yet, or you want more practice, then use the New York City property sales dataset today. Follow the instructions in the assignment notebook. [Here's a video walkthrough](https://youtu.be/pPWFw8UtBVg?t=584) you can refer to if you get stuck or want hints!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}